<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Algorithm on Wound:Abser&#39;s Blog</title>
    <link>https://blog.abser.top/tags/algorithm/</link>
    <description>Recent content in Algorithm on Wound:Abser&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 19 Dec 2018 17:38:01 +0800</lastBuildDate>
    
	<atom:link href="https://blog.abser.top/tags/algorithm/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>TokenBucket</title>
      <link>https://blog.abser.top/blog/tokenbucket/</link>
      <pubDate>Wed, 19 Dec 2018 17:38:01 +0800</pubDate>
      
      <guid>https://blog.abser.top/blog/tokenbucket/</guid>
      <description> TokenBucket 规则  每秒会有 Limit个令牌放入桶中，或者说，每过 1/Limit 秒桶中增加一个令牌 桶中最多存放 burst 个令牌，如果桶满了，新放入的令牌会被丢弃 当一个 n 单元的数据包到达时，消耗 n 个令牌，然后发送该数据包 如果桶中可用令牌小于 n，则该数据包将被缓存或丢弃  令牌桶算法 令牌桶算法是网络流量整形（Traffic Shaping）和速率限制（Rate Limiting）中最常使用的一种算法。典型情况下，令牌桶算法用来控制发送到网络上的数据的数目，并允许突发数据的发送。
RateLimiter中的令牌桶算法 简介 该包基于令牌桶算法(Token Bucket)来完成限流,非常易于使用.RateLimiter经常用于限制对一些物理资源或者逻辑资源的访问速率.它支持三种方式,： ·AllowN()是如果拿不到立刻返回。 ·WaitN()是暂时排队，等到足够的令牌再出发，中途可能因为context的cancel而cancel，同时归还占位。 ·ReserveN()是直接出发，但是前人挖坑后人填，下一次请求将为此付出代价，一直等到令牌亏空补上，并且桶中有足够本次请求使用的令牌为止。
工作实例 假设正在工作的一个RateLimiter
allow和wait 对一个每秒产生一个令牌的RateLimiter,每有一个没有使用令牌的一秒,我们就将tokens加 1 ,如果RateLimiter在 10 秒都没有使用,则tokens变成10.0.这个时候,一个请求到来并请求三个令牌,我们将从RateLimiter中的令牌为其服务,tokens变为7.0.这个请求之后立马又有一个请求到来并请求10个令牌,我们将从RateLimiter剩余的 7 个令牌给这个请求,剩下还需要三个令牌,我们将从RateLimiter新产生的令牌中获取.我们已经知道,RateLimiter每秒新产生 1 个令牌,就是说上面这个请求还需要的 3 个令牌就要求其等待 3 秒.
reserve 想象一个RateLimiter每秒产生一个令牌,现在完全没有使用(处于初始状态),如果一个昂贵的请求要求 100 个令牌.如果我们选择让这个请求等待100秒再允许其执行,这显然很荒谬.我们为什么什么也不做而只是傻傻的等待100秒,一个更好的做法是允许这个请求立即执行(和allow没有区别),然后将随后到来的请求推迟到正确的时间点.这种策略,我们允许这个昂贵的任务立即执行,并将随后到来的请求推迟100秒.这种策略就是让任务的执行和等待同时进行.
关于timeToAct 一个重要的结论:RateLimiter不会记最后一个请求,而是即下一个请求允许执行的时间.这也可以很直白的告诉我们到达下一个调度时间点的时间间隔.然后定一个一段时间未使用的Ratelimiter也很简单:下一个调度时间点已经过去,这个时间点和现在时间的差就是Ratelimiter多久没有被使用,我们会将这一段时间翻译成tokens.所有,如果每秒钟产生一个令牌(Limit==1),并且正好每秒来一个请求,那么tokens就不会增长.
burst RateLimiter有一个桶容量，当请求大于这个桶容量时，直接丢弃。
链接 ·__ __Golang实现RateLimiter源码导航 · RateLimiter语雀阅读 </description>
    </item>
    
    <item>
      <title>HyperLogLog</title>
      <link>https://blog.abser.top/blog/hyperloglog%E7%AE%97%E6%B3%95/</link>
      <pubDate>Sun, 25 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://blog.abser.top/blog/hyperloglog%E7%AE%97%E6%B3%95/</guid>
      <description>更好的阅读参见我的语雀
基数计数基本概念 基数计数(cardinality counting)通常用来统计一个集合中不重复的元素个数，例如统计某个网站的UV，或者用户搜索网站的关键词数量。数据分析、网络监控及数据库优化等领域都会涉及到基数计数的需求。 要实现基数计数，最简单的做法是记录集合中所有不重复的元素集合，当新来一个元素，若中不包含元素​，则将加入，否则不加入，计数值就是​的元素数量。这种做法存在两个问题：
 当统计的数据量变大时，相应的存储内存也会线性增长 当集合变大，判断其是否包含新加入元素​的成本变大  概率算法 实际上目前还没有发现更好的在大数据场景中准确计算基数的高效算法，因此在不追求绝对准确的情况下，使用概率算法算是一个不错的解决方案。概率算法不直接存储数据集合本身，通过一定的概率统计方法预估基数值，这种方法可以大大节省内存，同时保证误差控制在一定范围内。目前用于基数计数的概率算法包括:
 Linear Counting(LC)：早期的基数估计算法，LC在空间复杂度方面并不算优秀，实际上LC的空间复杂度与简单bitmap方法是一样的（但是有个常数项级别的降低），都是O(N​max​​)； LogLog Counting(LLC)：LogLog Counting相比于LC更加节省内存，空间复杂度只有O(log​2​​(log​2​​(N​max​​))) HyperLogLog Counting(HLL)：HyperLogLog Counting是基于LLC的优化和改进，在同样空间复杂度情况下，能够比LLC的基数估计误差更小。  HLL 直观演示 HLLDEMO
HLL的实际步骤  通过hash函数计算输入值对应的比特串 比特串的低 位对应的数字用来找到数组S中对应的位置 i t+1位开始找到第一个1出现的位置 k，将 k 记入数组位置 基于数组S记录的所有数据的统计值，计算整体的基数值，计算公式可以简单表示为：  HLL是LLC的误差改进，实际是基于LLC。
算法来源（N次伯努利过程） 下面非正式的从直观角度描述LLC算法的思想来源。
设a为待估集合（哈希后）中的一个元素，由上面对H的定义可知，a可以看做一个长度固定的比特串（也就是a的二进制表示），设H哈希后的结果长度为L比特，我们将这L个比特位从左到右分别编号为1、2、…、L：
又因为a是从服从均与分布的样本空间中随机抽取的一个样本，因此a每个比特位服从如下分布且相互独立。
 通俗说就是a的每个比特位为0和1的概率各为0.5，且相互之间是独立的。 设 ρ(a)为a的比特串中第一个“1”出现的位置，显然1≤ρ(a)≤L，这里我们忽略比特串全为0的情况（概率为）。如果我们遍历集合中所有元素的比特串，取为所有ρ(a)的最大值。 此时我们可以将作为基数的一个粗糙估计，即：  解释 注意如下事实：
由于比特串每个比特都独立且服从0-1分布，因此从左到右扫描上述某个比特串寻找第一个“1”的过程从统计学角度看是一个伯努利过程，例如，可以等价看作不断投掷一个硬币（每次投掷正反面概率皆为0.5），直到得到一个正面的过程。在一次这样的过程中，投掷一次就得到正面的概率为1/2，投掷两次得到正面的概率是，…，投掷k次才得到第一个正面的概率为。
现在考虑如下两个问题：
1、进行n次伯努利过程，所有投掷次数都不大于k的概率是多少？
2、进行n次伯努利过程，至少有一次投掷次数等于k的概率是多少？
首先看第一个问题，在一次伯努利过程中，投掷次数大于k的概率为，即连续掷出k个反面的概率。因此，在一次过程中投掷次数不大于k的概率为。因此，n次伯努利过程投掷次数均不大于k的概率为：
 显然第二个问题的答案是：
 从以上分析可以看出，当时，Pn(X≥k)的概率几乎为0，同时，当时，Pn(X≤k)的概率也几乎为0。用自然语言概括上述结论就是：当伯努利过程次数远远小于时，至少有一次过程投掷次数等于k的概率几乎为0；当伯努利过程次数远远大于时，没有一次过程投掷次数大于k的概率也几乎为0。
如果将上面描述做一个对应：一次伯努利过程对应一个元素的比特串，反面对应0，正面对应1，投掷次数k对应第一个“1”出现的位置，我们就得到了下面结论：
设一个集合的基数为n，为所有元素中首个“1”的位置最大的那个元素的“1”的位置，如果n远远小于，则我们得到为当前值的概率几乎为0（它应该更小），同样的，如果n远远大于，则我们得到为当前值的概率也几乎为0（它应该更大），因此可以作为基数n的一个粗糙估计。
以上结论可以总结为：进行了n次进行抛硬币实验，每次分别记录下第一次抛到正面的抛掷次数kk，那么可以用n次实验中最大的抛掷次数来预估实验组数量n： 
回到基数统计的问题，我们需要统计一组数据中不重复元素的个数，集合中每个元素的经过hash函数后可以表示成0和1构成的二进制数串，一个二进制串可以类比为一次抛硬币实验，1是抛到正面，0是反面。二进制串中从低位开始第一个1出现的位置可以理解为抛硬币试验中第一次出现正面的抛掷次数k，那么基于上面的结论，我们可以通过多次抛硬币实验的最大抛到正面的次数来预估总共进行了多少次实验，同样可以可以通过第一个1出现位置的最大值​来预估总共有多少个不同的数字（整体基数）。
LogLogCounting 均匀随机化 与LC一样，在使用LLC之前需要选取一个哈希函数H应用于所有元素，然后对哈希值进行基数估计。H必须满足如下条件（定性的）：
1、H的结果具有很好的均匀性，也就是说无论原始集合元素的值分布如何，其哈希结果的值几乎服从均匀分布（完全服从均匀分布是不可能的，D. Knuth已经证明不可能通过一个哈希函数将一组不服从均匀分布的数据映射为绝对均匀分布，但是很多哈希函数可以生成几乎服从均匀分布的结果，这里我们忽略这种理论上的差异，认为哈希结果就是服从均匀分布）。
2、H的碰撞几乎可以忽略不计。也就是说我们认为对于不同的原始值，其哈希结果相同的概率非常小以至于可以忽略不计。</description>
    </item>
    
  </channel>
</rss>